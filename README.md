#  Drone Surveillance Software

Welcome to **Drone Surveillance Software*, a Python-based real-time vision assistant that uses **OpenCV**, **speech recognition**, and **deep learning** to track **faces** and **objects** through live camera feeds â€” all **controlled by your voice**.

![Vision AI Banner](https://user-images.githubusercontent.com/placeholder/banner.png)

---

## ğŸ” Features

- ğŸ¤ **Voice-Controlled Interface** using Google Speech Recognition & pyttsx3  
- ğŸ§‘â€ğŸ¦° **Face Tracking** with Haar Cascade  
- ğŸ“¦ **Object Detection** using SSD MobileNet (COCO model)  
- ğŸ“¸ **Live Camera Streaming**  
- ğŸ›‘ **Real-time stopping & switching** between modules  
- ğŸ§  **Threaded execution** to keep UI responsive  

---

## ğŸ§° Tech Stack

- Python 3.x  
- OpenCV (cv2)  
- pyttsx3 (Text-to-Speech)  
- SpeechRecognition + Microphone  
- Pre-trained MobileNet SSD (COCO model)  
- Haarcascade Classifier  

---

## ğŸš€ How to Run

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/smart-vision-ai.git
cd smart-vision-ai
```

### 2. Install dependencies

```bash
pip install opencv-python numpy pyttsx3 SpeechRecognition
```

### 3. Download Model Files

- [`ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt`](https://github.com/opencv/opencv/blob/master/samples/dnn/face_detector/deploy.prototxt)
- [`frozen_inference_graph.pb`](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v3_large_coco_2020_01_14.tar.gz)
- [`coco.names`](https://github.com/pjreddie/darknet/blob/master/data/coco.names)

Place these files in the project directory.

### 4. Add your camera URL

Edit this line in the script:

```python
camera_url = 'your camera url'  # e.g., 0 for webcam
```

### 5. Run the application

```bash
python your_script_name.py
```

---

## ğŸ—£ Voice Commands Supported

- `"face tracking"` â€” Start face tracking  
- `"object tracking"` â€” Start object detection  
- `"stop"` â€” Stop the current module  
- `"exit"` â€” Exit the program  

---

## ğŸ’¡ Lessons Learned

- Multithreading in Python for responsive interaction  
- Real-time video feed handling  
- Using pre-trained models in OpenCV DNN module  
- Integrating voice input/output with AI systems  
- Clean module switching with global state  

---

## ğŸ¯ Example Use Case

```
Voice: "Object tracking"
>> Live camera opens with bounding boxes and labels for detected objects.

Voice: "Stop"
>> Tracking stops gracefully.

Voice: "Face tracking"
>> Camera starts detecting and highlighting faces.
```

---

## ğŸ“ File Structure

```
ğŸ“¦ smart-vision-ai/
 â”£ ğŸ“„ smart_vision.py
 â”£ ğŸ“„ ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt
 â”£ ğŸ“„ frozen_inference_graph.pb
 â”£ ğŸ“„ coco.names
```

---

## ğŸ“Œ Author

- **Your Name** â€“ [GitHub Profile](https://github.com/yourusername)

---

## ğŸ“œ License

This project is licensed under the MIT License.

---


